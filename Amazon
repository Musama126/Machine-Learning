#pip install pandas numpy nltk scikit-learn streamlit pillow
import nltk
nltk.download('punkt')

import numpy as np
import pandas as pd
import nltk
from nltk.stem.snowball import SnowballStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

import streamlit as st
from PIL import Image

# Load the dataset
df = pd.read_csv('amazon_product.csv')
df = df.drop('id', axis=1)

# Initialize the stemmer
stemmer = SnowballStemmer('english')

# Define the tokenizer and stemmer function
def tokenize_and_stem(text):
    tokens = nltk.word_tokenize(text.lower())
    stems = [stemmer.stem(t) for t in tokens]
    return stems

# Apply the tokenizer and stemmer to the DataFrame
df['stemmed_tokens'] = df.apply(lambda row: tokenize_and_stem(row['Title'] + " " + row['Description']), axis=1)

# Initialize the TF-IDF Vectorizer
tfidfv = TfidfVectorizer(tokenizer=tokenize_and_stem)

# Define the cosine similarity function
def cosine_sim(txt1, txt2):
    matrix = tfidfv.fit_transform([' '.join(txt1), ' '.join(txt2)])
    return cosine_similarity(matrix)[0, 1]

# Define the product search function
def search_product(query):
    stemmed_query = tokenize_and_stem(query)
    df['similarity'] = df['stemmed_tokens'].apply(lambda x: cosine_sim(stemmed_query, x))
    results = df.sort_values(by=['similarity'], ascending=False).head(10)[['Title', 'Description', 'Category']]
    return results

# Example usage
query = "wireless headphones"
results = search_product(query)
print(results)

# web app
img = Image.open('img.png')
st.image(img,width=600)
st.title("Search Engine and Product Recommendation System ON Am Data")
query = st.text_input("Enter Product Name")
sumbit = st.button('Search')
if sumbit:
    res = search_products(query)
    st.write(res)
